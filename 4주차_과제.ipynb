{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4주차 과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smarthumanism/FirstRepository/blob/master/4%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkL6PjwsI6L",
        "colab_type": "text"
      },
      "source": [
        "# 4주차 과제\n",
        "- 용어 정리\n",
        "- 딥러닝 강의 클론 코딩\n",
        "- 딥러닝 순전파 & 역전파 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEtDe6_uGgI",
        "colab_type": "text"
      },
      "source": [
        "## 1. 용어 정리\n",
        "\n",
        "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
        "\n",
        "* 2문장 이상 작성 해 주세요. \n",
        "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
        "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfwat8eurKZ",
        "colab_type": "text"
      },
      "source": [
        "__(예시)__\n",
        "### 심층 신경망\n",
        ": 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공신경망이다. 심층 신경망은 일반적으로 인공신경망과 마찬가지로 복잡한 비선형 관계들을 모델링 할 수 있다. 신층신경망의 목적은 분류 및 수치예측을 하기 위함이고 이미지 트레이닝이나 문자인식과 같은 분야에서 매우 유용하게 쓰이고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YJNKG_v65A",
        "colab_type": "text"
      },
      "source": [
        "### MCP 뉴런\n",
        ": 1943년 워랜 맥컬록과 월터 피츠가 간소화된 뇌의 뉴런 개념으로서 발표한 것으로, 화학적, 전기적 신호를 처리하고 전달하는 뇌의 신경세포를 모방한 것이다. 하나 이상의 이진 입력을 받아 하나의 이진 출력을 내는 간단한 논리 회로이다. 맥컬록과 피츠는 이 모델로 인공 뉴런의 네트워크를 만들어 어떤 논리 명제도 계산할 수 있음을 보였다.\n",
        "\n",
        "### 퍼셉트론\n",
        ": 1957년 프랭크 로젠블랫에 의해 고안된 인공신경망의 시초로서 자동으로 최적의 가중치를 학습하는 알고리즘이다. TLU(Threshold Logic Unit)이라는 인공 뉴런에 기반하는데, 입력과 출력이 수이고, 각각의 입력 연결은 가중치와 연관되어 있다. TLU는 입력의 가중치 합을 계산하고 그 결과에 계단 함수를 적용하여 결과를 출력한다. 각 출력 뉴런의 결정 경계가 선형이다는 한계가 있다.\n",
        "\n",
        "### 역전파\n",
        ": 제프리 힌튼이 제시한 알고리즘으로서 다층 퍼셉트론이 파라미터 개수가 많아지면서 가중치와 편향의 학습이 어려운 문제를 깔끔히 해결해주었다. 정방향 계산에서 오차를 측정하고 역방향으로 각 층을 거치면서 오차에 기여한 정도를 측정한 후 이에 따라 가중치를 조절하는 방법이다.\n",
        "\n",
        "### 강화학습\n",
        ": 지도 데이터가 없어서 보상을 기반으로 이루어지는 학습 알고리즘이다. 에이전트가 행동을 취하면 그에 따라 보상 및 패널티가 발생한다. 이미 보상이 알려진 경험된 행동 속에서 의사결정하는 것은 활용이라 하고, 무작위로 미지의 행동을 선택하는 것을 탐험이라 한다. 탐험의 비중이 커지면 학습 시간과 비용이 증가하고, 반대로 탐험이 없고 활용만 있으면 장기적인 추세에서 평균 보상의 증가에 한계가 있다. 따라서, 탐험과 활용의 적절한 균형과 조절이 중요한 학습 알고리즘이다.\n",
        "\n",
        "### 과적합\n",
        ":머신 러닝에서 학습 데이타를 과하게 학습하면, 학습 데이터에 대해서는 오차가 감소하지만, 실제 데이터에 대해서는 도리어 오차가 증가하는 문제를 말한다. 예를 들면, 결정트리학습에서 트리가 지나치게 깊어지다 보면 구조가 복잡해지고 계산 자원이 많이 필요하고 도리어 원하는 결과값에서 멀어지게 된다. \n",
        "\n",
        "### 차원의 저주\n",
        ":다뤄야 할 특성이 늘어 수학적 공간 차원이 늘어나면 문제의 계산법이 지수적으로 커지는 문제이다. 이는 차원 축소 기법, 표준화, 올바른 변수 선택 등을 통해 대처할 수 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zfFXLCy6jD",
        "colab_type": "text"
      },
      "source": [
        "## 2. 딥러닝 강의 클론 코딩\n",
        "\n",
        "####__퍼셉트론 구조 구현하기__ \n",
        "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
        " \n",
        "\n",
        "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
        "\n",
        "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46v0caefTmcM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "04a12e6d-1108-4b99-f440-b1034bc3ff01"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal([1],0,1)\n",
        "\n",
        "import math\n",
        "def sigmoid(x):\n",
        "  return 1/(1+math.exp(-x))\n",
        "\n",
        "output = sigmoid(x*w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000):\n",
        "  output = sigmoid(x*w)\n",
        "  error = y - output\n",
        "  w = w + x*0.1*error\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"학습 횟수:\", i, \"Error:\", error, \"예측 결과:\", output)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습 횟수: 99 Error: -0.10010598284299604 예측 결과: 0.10010598284299604\n",
            "학습 횟수: 199 Error: -0.05178399422833116 예측 결과: 0.05178399422833116\n",
            "학습 횟수: 299 Error: -0.034590451977903586 예측 결과: 0.034590451977903586\n",
            "학습 횟수: 399 Error: -0.02588962752851373 예측 결과: 0.02588962752851373\n",
            "학습 횟수: 499 Error: -0.020658699939863617 예측 결과: 0.020658699939863617\n",
            "학습 횟수: 599 Error: -0.017174253993457355 예측 결과: 0.017174253993457355\n",
            "학습 횟수: 699 Error: -0.014689506449480992 예측 결과: 0.014689506449480992\n",
            "학습 횟수: 799 Error: -0.012829497265431342 예측 결과: 0.012829497265431342\n",
            "학습 횟수: 899 Error: -0.011385568271837804 예측 결과: 0.011385568271837804\n",
            "학습 횟수: 999 Error: -0.010232493309882492 예측 결과: 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcc5mzI9oZ7r",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0cceeed0-0235-4b0f-af88-0b8c377d5b4b%2F_2020-06-09__9.35.23.png?table=block&id=88fd8912-9356-49a4-9fda-a1a63fe96ea9&width=2870&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0HVRk8fOom",
        "colab_type": "text"
      },
      "source": [
        "## 3. 딥러닝 순전파 & 역전파 계산\n",
        "\n",
        "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
        "\n",
        "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
        "\n",
        "\n",
        "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
        "\n",
        "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpwPFWhOUzww",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2OVY7w5U3CI",
        "colab_type": "text"
      },
      "source": [
        "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : 2\n",
        "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은? : 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJdIX1DWtt1L",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "* 참고 레퍼런스\n",
        "\n",
        " 핸즈온 머신러닝: 사이킷런과 텐서플로를 활용한 머신러닝, 딥러닝 실무(오렐리앙 제롱 저, 박해선 역), [제타위키](https://zetawiki.com/wiki/%EC%B0%A8%EC%9B%90%EC%9D%98_%EC%A0%80%EC%A3%BC)"
      ]
    }
  ]
}